
# ğŸ§  Parkinsonâ€™s Disease Detection from Speech using Deep Learning

## ğŸ“‹ Overview

This project detects **Parkinson's Disease** from voice recordings using a trained deep learning model based on **MFCC (Mel Frequency Cepstral Coefficients)** features. A **Keras model** is used to classify whether the uploaded speech sample indicates a healthy individual or one with Parkinsonâ€™s. The application is deployed using **Streamlit** for an intuitive web interface.

---

## âœ… Features

- ğŸ™ Upload a `.wav` audio file and get a real-time prediction
- ğŸ” Extract MFCC features using Librosa
- ğŸ§  Pre-trained Keras model (CNN/LSTM/Hybrid)
- ğŸ“ˆ Visualize MFCC spectrogram in the app
- ğŸ§ª Confidence score with prediction result

---

## ğŸ›  Tools & Technologies Used

- **Python**
- **TensorFlow / Keras**
- **Librosa**
- **NumPy**
- **Matplotlib**
- **Streamlit**

---

## ğŸš€ How It Works

1. User uploads a `.wav` audio file.
2. MFCC features are extracted using `librosa`.
3. Features are padded or trimmed to match model input size.
4. Model predicts whether the speaker has Parkinsonâ€™s or not.
5. Results and spectrogram are displayed in Streamlit.

---

## ğŸ“ File Structure

```
parkinsons-detector/
â”œâ”€â”€ app.py                  # Streamlit web app with model and feature extraction
â”œâ”€â”€ parkinson_model.h5      # Pre-trained model (place here)
â”œâ”€â”€ temp_audio.wav          # Temporary audio file (generated at runtime)
â”œâ”€â”€ README.md               # Project documentation (this file)
```

---

## ğŸ“¦ Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/parkinsons-detector.git
cd parkinsons-detector

# Create virtual environment (optional)
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows

# Install dependencies
pip install -r requirements.txt
```

---

## ğŸ§  Model Details

- Input: 40 MFCC coefficients over 150 time steps (reshaped to 1 x 40 x 150)
- Output: Probability of "Healthy" or "Parkinsonâ€™s"
- Model: Trained CNN/LSTM hybrid (details in training script)

---

## ğŸ§ª Usage

Run the Streamlit application:

```bash
streamlit run app.py
```

Upload a **WAV** file (speech sample) and view:

- MFCC Spectrogram
- Disease Prediction (Healthy / Parkinsonâ€™s)
- Confidence Score

---

## ğŸ” Sample Prediction

```
Prediction: Parkinson's
Confidence: 0.94
âš ï¸ High risk of Parkinson's detected. Consult a doctor.
```

---

## ğŸ§¾ Requirements (requirements.txt)

```txt
streamlit
numpy
librosa
matplotlib
tensorflow
```

---

## ğŸ§  Dataset & Training

- Dataset used: [UCI Parkinson's Telemonitoring Voice Dataset](https://archive.ics.uci.edu/ml/datasets/parkinsons+telemonitoring)
- MFCC features extracted with Librosa
- Trained on spectrogram slices using CNN/LSTM hybrid architecture

---

## ğŸ“Œ Future Improvements

- ğŸ™ Add real-time audio recording in the app
- ğŸ“Š Add voice signal pre-processing and augmentation
- ğŸ” Model retraining with larger datasets
- ğŸ¤– Deploy with Flask/FastAPI backend for mobile use

---

## ğŸ™Œ Author

Developed by **Akash**  
Machine Learning Engineer | 2025

---

## ğŸ“œ License

This project is licensed under the [MIT License](LICENSE).

---

## ğŸ¤ Contributions

Feel free to fork, contribute, or open issues.
